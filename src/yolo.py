import os, cv2, threading, speech_recognition as sr, pyttsx3
from ultralytics import YOLOWorld
from intent import IntentInference
from ocr import OCRProcessor

class YOLOWorldDetector:
    """YOLOWorld å®æ—¶æ£€æµ‹ + å¼‚æ­¥è¯­éŸ³ + å³æ—¶æ„å›¾æ¨ç† + OCR"""

    def __init__(self, classes=None, camera_index=1, show_window=False, verbose=False):
        os.environ["OPENCV_VIDEOIO_PRIORITY_MSMF"] = "0"
        self.verbose = verbose
        self.show_window = show_window
        self.camera_index = camera_index
        self.running = True

        self.model = YOLOWorld("../config/yolov8s-worldv2.pt")
        try:
            self.model.set_classes(classes or ["door", "chair", "table", "stairs", "person", "bicycle", "car"])
        except Exception as e:
            print("CLIP æ¨¡å‹åŠ è½½å¤±è´¥:", e)

        self.cap = cv2.VideoCapture(self.camera_index)
        if not self.cap.isOpened():
            raise RuntimeError("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        # ä¿®å¤ï¼šç§»é™¤ cv2.startWindowThread()ï¼Œç›´æ¥åˆ›å»ºçª—å£
        if self.show_window:
            cv2.namedWindow("YOLOWorld - Detection", cv2.WINDOW_NORMAL)

        # === åˆå§‹åŒ–OCRå¤„ç†å™¨ ===
        self.ocr_processor = OCRProcessor(enabled=True, process_interval=5)

        # === åˆå§‹åŒ–æ„å›¾æ¨ç†å¼•æ“ ===
        self.intent_engine = IntentInference(output_func=self.speak_response)
        self.last_detections = []

        # === å¯åŠ¨è¯­éŸ³ç›‘å¬çº¿ç¨‹ ===
        threading.Thread(target=self.listen_command, daemon=True).start()

    # ---------------------------- è¯­éŸ³ç›‘å¬ ----------------------------
    def listen_command(self):
        rec = sr.Recognizer()
        while self.running:
            try:
                with sr.Microphone(sample_rate=8000) as src:
                    rec.adjust_for_ambient_noise(src, duration=0.5)
                    print("ğŸ¤ æ­£åœ¨ç›‘å¬è¯­éŸ³æŒ‡ä»¤...")
                    audio = rec.listen(src, timeout=5, phrase_time_limit=4)
                    cmd = rec.recognize_google(audio, language='en-US') #zh-CNæ˜¯ä¸­æ–‡
                    cmd = cmd.strip().lower()  # ç»Ÿä¸€å°å†™å¤„ç†
                    print(f"ğŸ—£ï¸ è¯†åˆ«åˆ°è¯­éŸ³æŒ‡ä»¤: {cmd}")
                    # ç›´æ¥è°ƒç”¨å³æ—¶æ„å›¾æ¨ç†
                    self.intent_engine.infer_now(cmd)
            except sr.WaitTimeoutError:
                continue
            except Exception:
                continue

    # ---------------------------- å¼‚æ­¥è¯­éŸ³æ’­æŠ¥ ----------------------------
    def speak_response(self, response):
        def _speak():
            print(f"[ğŸ§  æ„å›¾ç»“æœ] {response}")
            try:
                engine = pyttsx3.init()
                engine.setProperty('rate', 170)
                engine.say(response)
                engine.runAndWait()
            except Exception as e:
                print(f"è¯­éŸ³åˆæˆé”™è¯¯: {e}")

        threading.Thread(target=_speak, daemon=True).start()

    # ---------------------------- ä¸»æ£€æµ‹å¾ªç¯ ----------------------------
    def run(self):
        frame_count = 0
        skip_interval = 5  # è¶Šå¤§è¶Šæµç•…ï¼Œè¶Šå°è¶Šå‡†

        while self.running:
            ret, frame = self.cap.read()
            if not ret: break

            frame_count += 1
            if frame_count % skip_interval != 0:
                if self.show_window:
                    cv2.imshow("YOLOWorld - Detection", frame)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
                continue

            # YOLOç›®æ ‡æ£€æµ‹
            results = self.model.predict(frame, imgsz=320, verbose=False)
            r = results[0]
            detections = [
                {"class": r.names[int(b.cls[0])],
                 "confidence": float(b.conf[0]),
                 "bbox": list(map(int, b.xyxy[0]))}
                for b in r.boxes
            ]
            self.last_detections = detections

            # æ›´æ–°æ„å›¾å¼•æ“çš„è§†è§‰ä¿¡æ¯ï¼ˆåŒ…å«OCRç»“æœï¼‰
            ocr_results = self.ocr_processor.get_ocr_results()
            self.intent_engine.update_vision(detections, ocr_results)

            # å¼‚æ­¥å¤„ç†OCRï¼ˆä¸é˜»å¡ä¸»è¿›ç¨‹ï¼‰
            self.ocr_processor.process_frame_async(frame)

            if self.show_window:
                annotated = r.plot()

                # åœ¨ç”»é¢ä¸Šæ˜¾ç¤ºOCRç»“æœ
                if ocr_results:
                    y_offset = 30
                    for i, ocr_item in enumerate(ocr_results[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                        text = f"Text: {ocr_item['text']}"
                        cv2.putText(annotated, text, (10, y_offset),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                        y_offset += 25

                cv2.imshow("YOLOWorld - Detection", annotated)
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q') or key == 27:  # 27æ˜¯ESCé”®
                    break

        self.running = False
        self.cap.release()
        if self.show_window:
            cv2.destroyAllWindows()


if __name__ == "__main__":
    detector = YOLOWorldDetector(
        classes=[
            # ğŸ‘¤ äººä½“æ•´ä½“
            "boy", "girl",

            # ğŸ§  äººä½“éƒ¨ä½
            "head", "face", "eye", "nose", "mouth", "ear", "hair",
            "hand", "arm", "shoulder", "elbow", "wrist",
            "leg", "knee", "foot", "ankle", "toe",
            "neck", "back", "chest", "belly", "waist",

            # ğŸ‘• ç©¿æˆ´
            "shirt", "jacket", "coat", "pants", "shorts", "dress", "skirt", "shoe",
            "hat", "cap", "helmet", "mask", "scarf", "gloves", "bag", "backpack", "watch",

            # ğŸª‘ ç¯å¢ƒç±»ï¼ˆå¯ä¿æŒå®Œæ•´åˆ—è¡¨ï¼‰
            "door", "window", "stairs", "chair", "table", "sofa", "bed", "tv", "monitor",
            "laptop", "keyboard", "mouse", "phone", "cup", "bottle", "book", "lamp",
            "mirror", "refrigerator", "sink", "toilet", "microwave", "oven",

            # ğŸš— æˆ·å¤–/äº¤é€š
            "car", "bus", "truck", "bicycle", "motorcycle", "train", "airplane",
            "boat", "traffic light", "stop sign", "bench", "bridge", "crosswalk",

            # ğŸ¶ åŠ¨ç‰©
            "dog", "cat", "bird", "horse", "cow", "sheep", "elephant", "zebra", "giraffe",

            # âš ï¸ éšœç¢ä¸ç¯å¢ƒ
            "wall", "floor", "pole", "cone", "barrier", "tree", "bush", "grass",

            # ğŸ½ï¸ æ—¥ç”¨å“
            # "knife", "fork", "spoon", "plate"
            "bowl", "cup", "bottle", "can", "pen", "paper"

            # ğŸ§° å…¶ä»–
            "bag", "box", "bucket", "bin", "remote", "umbrella", "broom", "trash can"
        ],
        show_window=True,
        verbose=False
    )

    detector.run()